import torch
from pdp_generator import NODE_DEPOT, NODE_PICKUP, NODE_DELIVERY

class PDPEnv:
    """
    PDP ç¯å¢ƒï¼šè½¦è¾†å¿…é¡»å…ˆåˆ°å–è´§ç‚¹å–è´§åæ‰èƒ½é€è´§ï¼Œå—è½¦è¾†å®¹é‡çº¦æŸï¼Œç¯å¢ƒä¸­æ›´æ–°ç´¯è®¡è¡Œé©¶è·ç¦»æ—¶é‡‡ç”¨é¢„è®¡ç®—çš„åœ°å›¾çœŸå®è·ç¦»ã€‚
    """
    def __init__(self, vehicle_capacity=20):
        self.vehicle_capacity = vehicle_capacity

    def reset(self, data):
        """
        æ ¹æ®ç”Ÿæˆçš„æ•°æ®é‡ç½®ç¯å¢ƒï¼Œåˆå§‹åŒ–å„ç±»çŠ¶æ€
        è¿”å› state å­—å…¸ï¼ŒåŒ…å«ï¼š
          - locsã€node_typeã€order_mapã€order_load
          - current_node (è½¦è¾†å½“å‰ä½ç½®)ã€visited (å·²è®¿é—®èŠ‚ç‚¹)
          - pickup_doneã€delivery_doneï¼ˆè®¢å•çŠ¶æ€ï¼‰
          - current_loadï¼ˆè½¦è¾†è½½è·ï¼‰ã€total_distanceï¼ˆç´¯è®¡è¡Œé©¶è·ç¦»ï¼‰
          - doneï¼ˆæ˜¯å¦å®Œæˆæ‰€æœ‰è®¢å•ï¼‰
          - action_maskï¼ˆåˆæ³•åŠ¨ä½œ maskï¼‰
        """
        state = {}
        state["locs"] = data["locs"]
        state["node_type"] = data["node_type"]
        state["order_map"] = data["order_map"]
        state["order_load"] = data["order_load"]
        batch_size, num_nodes, _ = state["locs"].shape
        num_orders = data["num_orders"]

        state["current_node"] = torch.zeros(batch_size, dtype=torch.int64)  # åˆå§‹åœ¨ depot
        state["visited"] = torch.zeros(batch_size, num_nodes, dtype=torch.bool)
        state["visited"][:, 0] = True  # depot è§†ä¸ºå·²è®¿é—®

        state["pickup_done"] = torch.zeros(batch_size, num_orders, dtype=torch.bool)
        state["delivery_done"] = torch.zeros(batch_size, num_orders, dtype=torch.bool)
        state["current_load"] = torch.zeros(batch_size, dtype=torch.int32)
        state["total_distance"] = torch.zeros(batch_size, dtype=torch.float32)
        state["done"] = torch.zeros(batch_size, dtype=torch.bool)

        state["action_mask"] = self.update_action_mask(state)
        return state

    def update_action_mask(self, state):
        """
        æ ¹æ®å½“å‰çŠ¶æ€æ›´æ–°åŠ¨ä½œ maskï¼š
          - å·²è®¿é—®èŠ‚ç‚¹å’Œ depot å‡ä¸å¯é€‰
          - å¯¹äºå–è´§èŠ‚ç‚¹ï¼šå½“è½¦è¾†åŠ ä¸Šè¯¥è®¢å•è´Ÿè½½ä¸è¶…å‡º capacity æ—¶å…è®¸
          - å¯¹äºé€è´§èŠ‚ç‚¹ï¼šä»…å½“å¯¹åº”è®¢å•å·²å–è´§ä¸”æœªé€è´§æ—¶å…è®¸
        è¿”å›ï¼šBoolean tensor (batch_size, num_nodes)
        """
        batch_size, num_nodes, _ = state["locs"].shape
        mask = torch.zeros(batch_size, num_nodes, dtype=torch.bool)
        for b in range(batch_size):
            for n in range(num_nodes):
                if state["visited"][b, n]:
                    mask[b, n] = False
                    continue
                if state["node_type"][b, n] == NODE_DEPOT:
                    mask[b, n] = False
                    continue
                if state["node_type"][b, n] == NODE_PICKUP:
                    order_id = state["order_map"][b, n].item()
                    load = state["order_load"][b, order_id].item()
                    if state["current_load"][b] + load <= self.vehicle_capacity:
                        mask[b, n] = True
                    else:
                        mask[b, n] = False
                    continue
                if state["node_type"][b, n] == NODE_DELIVERY:
                    order_id = state["order_map"][b, n].item()
                    if state["pickup_done"][b, order_id] and (not state["delivery_done"][b, order_id]):
                        mask[b, n] = True
                    else:
                        mask[b, n] = False
                    continue
        return mask

    def step(self, state, actions, distance_matrix):
        """
        æ ¹æ®åŠ¨ä½œ actions æ›´æ–°çŠ¶æ€ï¼Œä½¿ç”¨é¢„å…ˆè®¡ç®—çš„ distance_matrix æ›´æ–°ç´¯è®¡è·ç¦»
        å‚æ•°:
          state: å½“å‰çŠ¶æ€å­—å…¸
          actions: tensor (batch_size,) å„å®ä¾‹é€‰å–çš„èŠ‚ç‚¹ç´¢å¼•
          distance_matrix: é¢„è®¡ç®—çš„è·ç¦»çŸ©é˜µ (num_nodes, num_nodes)
        è¿”å›æ›´æ–°åçš„ state
        """
        batch_size, num_nodes, _ = state["locs"].shape
        new_state = state.copy()
        new_state["visited"] = state["visited"].clone()
        new_state["pickup_done"] = state["pickup_done"].clone()
        new_state["delivery_done"] = state["delivery_done"].clone()
        new_state["current_load"] = state["current_load"].clone()
        new_state["total_distance"] = state["total_distance"].clone()
        new_state["done"] = state["done"].clone()

        for b in range(batch_size):
            if state["done"][b]:
                continue
            current = state["current_node"][b].item()
            next_node = actions[b].item()
            # ä½¿ç”¨åœ°å›¾çœŸå®è·ç¦»
            dist = distance_matrix[current][next_node]
            new_state["total_distance"][b] += dist
            new_state["current_node"][b] = actions[b]
            new_state["visited"][b, next_node] = True

            node_type = state["node_type"][b, next_node].item()
            if node_type == NODE_PICKUP:
                order_id = state["order_map"][b, next_node].item()
                new_state["pickup_done"][b, order_id] = True
                load = state["order_load"][b, order_id].item()
                new_state["current_load"][b] += load
            elif node_type == NODE_DELIVERY:
                order_id = state["order_map"][b, next_node].item()
                if state["pickup_done"][b, order_id]:
                    new_state["delivery_done"][b, order_id] = True
                    load = state["order_load"][b, order_id].item()
                    new_state["current_load"][b] -= load
            if torch.all(new_state["pickup_done"][b]) and torch.all(new_state["delivery_done"][b]):
                new_state["done"][b] = True

        new_state["action_mask"] = self.update_action_mask(new_state)
        return new_state

    def get_reward(self, state):
        """
        ä»¥è´Ÿç´¯è®¡è·ç¦»ä½œä¸ºå¥–åŠ±ï¼ˆç›®æ ‡ä¸ºæœ€å°åŒ–è¿è¾“è·ç¦»ï¼‰
        """
        return -state["total_distance"]

    def render(self, state):
        """
        æ‰“å°å½“å‰çŠ¶æ€ä¿¡æ¯ï¼Œä¾¿äºè§‚å¯Ÿ
        """
        batch_size, num_nodes, _ = state["locs"].shape
        for b in range(batch_size):
            print(f"å®ä¾‹ {b}:")
            print(f"  å½“å‰èŠ‚ç‚¹: {state['current_node'][b].item()}")
            print(f"  å½“å‰è½½è·: {state['current_load'][b].item()}")
            print(f"  ç´¯è®¡è·ç¦»: {state['total_distance'][b].item():.2f}")
            print(f"  pickup_done: {state['pickup_done'][b].tolist()}")
            print(f"  delivery_done: {state['delivery_done'][b].tolist()}")
            print(f"  done: {state['done'][b].item()}")
            print("------------")

def greedy_policy(state, env, distance_matrix):
    """
    è´ªå¿ƒç­–ç•¥ï¼šæ ¹æ®è·ç¦»çŸ©é˜µé€‰æ‹©å½“å‰åˆæ³•åŠ¨ä½œä¸­è·ç¦»æœ€è¿‘çš„èŠ‚ç‚¹
    å‚æ•°:
      state: å½“å‰çŠ¶æ€
      env: PDPEnvï¼ˆç”¨äºè·å–çŠ¶æ€ä¿¡æ¯ï¼‰
      distance_matrix: é¢„è®¡ç®—çš„è·ç¦»çŸ©é˜µ
    è¿”å›:
      tensor (batch_size,) å„å®ä¾‹é€‰å–çš„èŠ‚ç‚¹ç´¢å¼•
    """
    batch_size, num_nodes, _ = state["locs"].shape
    actions = torch.zeros(batch_size, dtype=torch.int64)
    for b in range(batch_size):
        if state["done"][b]:
            actions[b] = state["current_node"][b]
            continue
        current = state["current_node"][b].item()
        # ä»å½“å‰èŠ‚ç‚¹åœ¨ distance_matrix ä¸­å–å‡ºè·ç¦»å‘é‡
        dists = torch.tensor(distance_matrix[current])
        mask = state["action_mask"][b]
        dists[~mask] = float("inf")
        if torch.all(torch.isinf(dists)):
            actions[b] = current
        else:
            actions[b] = torch.argmin(dists)
    return actions

def rollout(env, state, distance_matrix, policy=greedy_policy, max_steps=50):
    """
    æ ¹æ® policy è¿›è¡Œ rolloutï¼Œç›´è‡³æ‰€æœ‰å®ä¾‹å®Œæˆæˆ–è¾¾åˆ°æœ€å¤§æ­¥æ•°ã€‚
    æ‰“å°æ¯ä¸€æ­¥çš„è·¯å¾„ä¿¡æ¯ã€é…é€çŠ¶æ€ã€‚
    è¿”å›æœ€ç»ˆçŠ¶æ€å’Œè½¨è¿¹è®°å½•ï¼ˆæ¯å®ä¾‹æ¯æ­¥é€‰æ‹©çš„èŠ‚ç‚¹ç´¢å¼•åˆ—è¡¨ï¼‰ã€‚
    """
    batch_size = state["locs"].shape[0]
    trajectories = [[] for _ in range(batch_size)]
    steps = 0

    while not torch.all(state["done"]) and steps < max_steps:
        actions = policy(state, env, distance_matrix)
        for b in range(batch_size):
            if state["done"][b]:
                continue
            current = state["current_node"][b].item()
            next_node = actions[b].item()
            dist = distance_matrix[current][next_node]
            print(f"\nğŸ§­ å®ä¾‹ {b} - æ­¥éª¤ {steps + 1}")
            print(f"  ä»èŠ‚ç‚¹ {current} -> {next_node}ï¼Œæœ¬æ¬¡è·ç¦»: {dist:.2f} km")
            print(f"  å½“å‰ç´¯è®¡è·ç¦»: {state['total_distance'][b].item():.2f} km")
            print(f"  å½“å‰è½½è·: {state['current_load'][b].item()}")
            print(f"  å·²å–è´§è®¢å•: {state['pickup_done'][b].tolist()}")
            print(f"  å·²é€è¾¾è®¢å•: {state['delivery_done'][b].tolist()}")

        for b in range(batch_size):
            trajectories[b].append(actions[b].item())

        state = env.step(state, actions, distance_matrix)
        steps += 1

    return state, trajectories

