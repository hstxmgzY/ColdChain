augment_fn: dihedral8
baseline: shared
baseline_kwargs: {}
batch_size: 128
data_dir: data/
dataloader_num_workers: 0
env: !!python/object:pdp_env_rl4co.PDPEnv
  generator: !!python/object:pdp_generator_rl4co.PDPGenerator
    coord_range: !!python/tuple
    - &id001 !!python/tuple
      - 0
      - 1
    - *id001
    num_loc: 11
    num_orders: 5
  name: pdp
  vehicle_capacity: 10
feats: null
first_aug_identity: true
generate_default_data: false
log_on_step: true
lr_scheduler: MultiStepLR
lr_scheduler_interval: epoch
lr_scheduler_kwargs:
  gamma: 0.1
  milestones:
  - 9000
lr_scheduler_monitor: val/reward
metrics: {}
moe_kwargs:
  decoder:
    k: 2
    light_version: false
    noisy_gating: true
    num_experts: 4
  encoder:
    hidden_act: ReLU
    k: 2
    noisy_gating: true
    num_experts: 4
num_augment: 8
num_starts: null
optimizer: Adam
optimizer_kwargs:
  lr: 0.0001
  weight_decay: 1.0e-06
policy_kwargs:
  moe_kwargs:
    decoder:
      k: 2
      light_version: false
      noisy_gating: true
      num_experts: 4
    encoder:
      hidden_act: ReLU
      k: 2
      noisy_gating: true
      num_experts: 4
  normalization: instance
  num_encoder_layers: 6
  use_graph_context: false
reward_scale: null
shuffle_train_dataloader: false
test_batch_size: null
test_data_size: 10000
train_data_size: 10000
val_batch_size: 100
val_data_size: 1000
