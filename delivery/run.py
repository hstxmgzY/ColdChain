import argparse
import torch
import numpy as np
from pdp_generator import PDPGenerator
from pdp_env import PDPEnv, rollout, greedy_policy
from map_api import compute_distance_matrix, generate_static_map_url


def main():
    parser = argparse.ArgumentParser(description="PDP è·¯å¾„è§„åˆ’å¸¦åœ°å›¾ API é›†æˆ")
    parser.add_argument("--batch_size", type=int, default=1, help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--num_orders", type=int, default=3, help="æ¯ä¸ªå®ä¾‹è®¢å•æ•°é‡")
    args = parser.parse_args()

    # ç”Ÿæˆ PDP æ•°æ®
    generator = PDPGenerator(num_orders=args.num_orders)
    data = generator.generate(batch_size=args.batch_size)

    locs_np = data["locs"].squeeze(0).numpy()

    print("é¢„è®¡ç®—è·ç¦»çŸ©é˜µï¼Œè¯·ç¨å€™...")
    distance_matrix = compute_distance_matrix(locs_np)  # ğŸ”„ ä¸å†ä¼  api_key
    print("è·ç¦»çŸ©é˜µé¢„è®¡ç®—å®Œæˆã€‚")

    # åˆå§‹åŒ–ç¯å¢ƒ
    env = PDPEnv(vehicle_capacity=20)
    state = env.reset(data)
    print("åˆå§‹çŠ¶æ€:")
    env.render(state)

    final_state, trajectories = rollout(env, state, distance_matrix, policy=greedy_policy, max_steps=50)
    print("\næœ€ç»ˆçŠ¶æ€:")
    env.render(final_state)
    for b in range(args.batch_size):
        print(f"å®ä¾‹ {b} çš„è½¨è¿¹: {trajectories[b]}")
    reward = env.get_reward(final_state)
    print("\nå¥–åŠ± (è´Ÿç´¯è®¡è·ç¦»):", reward.tolist())
    print("\né…é€è·¯å¾„åœ°å›¾é“¾æ¥ï¼š")
    for b in range(args.batch_size):
        locs = data["locs"][b].numpy()
        traj = trajectories[b]
        map_url = generate_static_map_url(locs, traj)
        print(f"å®ä¾‹ {b} è·¯å¾„å›¾ï¼š{map_url}")

if __name__ == "__main__":
    main()


